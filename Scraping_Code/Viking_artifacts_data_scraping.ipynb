{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code BELOW should not be run again!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a list to store the data for each individual page\n",
    "all_data = {}\n",
    "\n",
    "# Initialize the web driver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "# Initial search page URL\n",
    "url = \"https://samlingar.shm.se/sok?type=object&productionPeriod=Vikingatid&hasImage=1&category=Arkeologisk%20samling&category=Vapen%20och%20rustningar&listType=archaeological&rows=500&offset=0\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load (you may need to adjust the sleep duration)\n",
    "time.sleep(2)\n",
    "\n",
    "# Find the cookie disclaimer button by its aria-label\n",
    "cookie_disclaimer = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Godkänn alla kakor\"]')\n",
    "# Check if the cookie disclaimer button is displayed and then click it\n",
    "if cookie_disclaimer.is_displayed():\n",
    "    ActionChains(driver).move_to_element(cookie_disclaimer).click().perform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from the main table\n",
    "table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "df = pd.read_html(table.get_attribute('outerHTML'))[0]\n",
    "\n",
    "# Drop the 'Bild' column\n",
    "if 'Bild' in df.columns:\n",
    "    df.drop(columns=['Bild'], inplace=True)\n",
    "\n",
    "# Extract museum names from the 'title' attribute of each <i> element\n",
    "museum_elements = driver.find_elements(By.CSS_SELECTOR, \"td i.museum-icon\")\n",
    "museum_names = [elem.get_attribute('title') for elem in museum_elements]\n",
    "\n",
    "# Replace the 'Museum' column with extracted text\n",
    "if 'Museum' in df.columns and len(museum_names) == len(df):\n",
    "    df['Museum'] = museum_names\n",
    "else:\n",
    "    print(\"Mismatch in number of rows while extracting museum names\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect names and href links for each item\n",
    "item_link = [(item.get_attribute('href')) for item in driver.find_elements(By.CLASS_NAME, \"archaeological-list__link\")]\n",
    "\n",
    "item_names = [f\"{item.text} - {index+1}\" for index, item in enumerate(driver.find_elements(By.CLASS_NAME, \"archaeological-list__link\"))]\n",
    "df['Unique Name'] = item_names\n",
    "df['Catalog Link'] = item_link\n",
    "\n",
    "# Initialize a column for extra details\n",
    "df['Extra Details'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to each item's link and scrape additional details\n",
    "for index, link in enumerate(df['Catalog Link']):\n",
    "    driver.get(link)\n",
    "\n",
    "    # Scrape the details from the item's page\n",
    "    item_details = {}\n",
    "    item_tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "    for item_table in item_tables:\n",
    "        item_df = pd.read_html(item_table.get_attribute('outerHTML'))[0]\n",
    "        for row in item_df.itertuples(index=False):\n",
    "            item_details[row[0]] = row[1]\n",
    "\n",
    "    # Store the scraped details as JSON in the DataFrame\n",
    "    df.at[index, 'Extra Details'] = json.dumps(item_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Föremålsbenämning</th>\n",
       "      <th>Föremålsnr.</th>\n",
       "      <th>Förvärvsnr.</th>\n",
       "      <th>Andra nummer</th>\n",
       "      <th>Material</th>\n",
       "      <th>Plats</th>\n",
       "      <th>Fornlämning</th>\n",
       "      <th>Socken</th>\n",
       "      <th>Landskap</th>\n",
       "      <th>Land</th>\n",
       "      <th>Kontexttyp</th>\n",
       "      <th>Kontextnr.</th>\n",
       "      <th>Artbedömning</th>\n",
       "      <th>Benslagsbedömning</th>\n",
       "      <th>Museum</th>\n",
       "      <th>Unique Name</th>\n",
       "      <th>Catalog Link</th>\n",
       "      <th>Extra Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spjut</td>\n",
       "      <td>371667_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 581</td>\n",
       "      <td>Järn</td>\n",
       "      <td>Björkö, Norr om Borg</td>\n",
       "      <td>L2017:1478</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Spjut - 1</td>\n",
       "      <td>https://samlingar.shm.se/object/58928958-A16E-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spjut</td>\n",
       "      <td>371668_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 581</td>\n",
       "      <td>Järn</td>\n",
       "      <td>Björkö, Norr om Borg</td>\n",
       "      <td>L2017:1478</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Spjut - 2</td>\n",
       "      <td>https://samlingar.shm.se/object/EFCC758B-B6BB-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Svärd Petersen Y</td>\n",
       "      <td>263086_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 752B</td>\n",
       "      <td>Järn</td>\n",
       "      <td>Björkö, Hemlanden</td>\n",
       "      <td>L2017:1904</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>752B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Svärd Petersen Y - 3</td>\n",
       "      <td>https://samlingar.shm.se/object/FFCD05E4-1460-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tveeggat svärd</td>\n",
       "      <td>263468_HST</td>\n",
       "      <td>34000</td>\n",
       "      <td>Undernummer: Bj 542</td>\n",
       "      <td>Järn</td>\n",
       "      <td>Björkö, Norr om Borg</td>\n",
       "      <td>L2017:1478</td>\n",
       "      <td>Adelsö socken</td>\n",
       "      <td>Uppland</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>Kammargrav</td>\n",
       "      <td>542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Tveeggat svärd - 4</td>\n",
       "      <td>https://samlingar.shm.se/object/7D599E53-A81D-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Svärd Petersen Y</td>\n",
       "      <td>264449_HST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FID: 264449</td>\n",
       "      <td>Järn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sverige</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historiska museet</td>\n",
       "      <td>Svärd Petersen Y - 5</td>\n",
       "      <td>https://samlingar.shm.se/object/CD8214A7-2FFB-...</td>\n",
       "      <td>{\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Föremålsbenämning Föremålsnr. Förvärvsnr.          Andra nummer Material  \\\n",
       "0             Spjut  371667_HST       34000   Undernummer: Bj 581     Järn   \n",
       "1             Spjut  371668_HST       34000   Undernummer: Bj 581     Järn   \n",
       "2  Svärd Petersen Y  263086_HST       34000  Undernummer: Bj 752B     Järn   \n",
       "3    Tveeggat svärd  263468_HST       34000   Undernummer: Bj 542     Järn   \n",
       "4  Svärd Petersen Y  264449_HST         NaN           FID: 264449     Järn   \n",
       "\n",
       "                  Plats Fornlämning         Socken Landskap     Land  \\\n",
       "0  Björkö, Norr om Borg  L2017:1478  Adelsö socken  Uppland  Sverige   \n",
       "1  Björkö, Norr om Borg  L2017:1478  Adelsö socken  Uppland  Sverige   \n",
       "2     Björkö, Hemlanden  L2017:1904  Adelsö socken  Uppland  Sverige   \n",
       "3  Björkö, Norr om Borg  L2017:1478  Adelsö socken  Uppland  Sverige   \n",
       "4                   NaN         NaN            NaN      NaN  Sverige   \n",
       "\n",
       "   Kontexttyp Kontextnr.  Artbedömning  Benslagsbedömning             Museum  \\\n",
       "0  Kammargrav        581           NaN                NaN  Historiska museet   \n",
       "1  Kammargrav        581           NaN                NaN  Historiska museet   \n",
       "2  Kammargrav       752B           NaN                NaN  Historiska museet   \n",
       "3  Kammargrav        542           NaN                NaN  Historiska museet   \n",
       "4         NaN        NaN           NaN                NaN  Historiska museet   \n",
       "\n",
       "            Unique Name                                       Catalog Link  \\\n",
       "0             Spjut - 1  https://samlingar.shm.se/object/58928958-A16E-...   \n",
       "1             Spjut - 2  https://samlingar.shm.se/object/EFCC758B-B6BB-...   \n",
       "2  Svärd Petersen Y - 3  https://samlingar.shm.se/object/FFCD05E4-1460-...   \n",
       "3    Tveeggat svärd - 4  https://samlingar.shm.se/object/7D599E53-A81D-...   \n",
       "4  Svärd Petersen Y - 5  https://samlingar.shm.se/object/CD8214A7-2FFB-...   \n",
       "\n",
       "                                       Extra Details  \n",
       "0  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "1  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "2  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "3  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  \n",
       "4  {\"Museum\": \"Historiska museet\", \"F\\u00f6rem\\u0...  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Replace '-' with NaNs in the entire DataFrame\n",
    "df.replace('-', np.NaN, inplace=True)\n",
    "\n",
    "df.head()  # Display the first few rows of the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Viking_war_artifacts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code ABOVE should not be run again!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are my own functions that help clean the data\n",
    "\n",
    "def search_columns_for_substring(columns, substring):\n",
    "    return [col for col in columns if substring in col]\n",
    "\n",
    "# this function counts how many empty values are in each column for a data set (use this after the drop col function to verify)\n",
    "def count_nans_in_dataframe(df):\n",
    "    nan_counts = df.isna().sum()\n",
    "    return pd.DataFrame({'Column': nan_counts.index, 'NaN Count': nan_counts.values})\n",
    "\n",
    "# this function drops columns that do not meet the minimum threshold\n",
    "# if by=\"count\" then drop columns that don't have at least that many populated fields\n",
    "    # ie. by_val=100 drops columns that have less than 100 populated rows\n",
    "# if by=\"prop\" then drop columns that don't have at least by_val% populated rows\n",
    "    # ie. by_val=0.05 drops columns that aren't at least 5% populated\n",
    "# if by=\"field\" then drop columns that have more missing values than the columns specified\n",
    "    # ie. by_val=\"Last_Device_Array.anv\" will keep Last_Device_Array.anv but drop any cols that have more missing values than Last_Device_Array.anv\n",
    "def drop_columns_with_fewer_nans(df, by=\"prop\", by_val=\"0.05\"):\n",
    "    if by == \"count\":\n",
    "        threshold = float(by_val)\n",
    "    elif by == \"prop\": threshold = round(df.shape[0]*float(by_val))\n",
    "    elif by == \"field\": threshold = df.shape[0]-df[by_val].isna().sum()\n",
    "    cols_to_drop = []\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > df.shape[0]-threshold:\n",
    "            cols_to_drop.append(col)\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    return df\n",
    "\n",
    "# this function to drops columns with duplicate names\n",
    "def drop_duplicate_columns(df):\n",
    "    duplicates = df.columns[df.columns.duplicated(keep='first')]\n",
    "    df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Extra Details'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Extra Details'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/aly.milne/Library/CloudStorage/OneDrive-BrighamYoungUniversity/Fall 2023/STAT 386/ST386_Final_Project/Scraped_Data/Viking_war_artifacts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# unpack json\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtra Details\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExtra Details\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(json\u001b[38;5;241m.\u001b[39mloads)\n\u001b[1;32m      7\u001b[0m war_artifacts_exploded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(dataset\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# drop rows that are not at least 25% populated\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Extra Details'"
     ]
    }
   ],
   "source": [
    "###### UNPACK JSON: WAR ARTIFACTS\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('/Users/aly.milne/Library/CloudStorage/OneDrive-BrighamYoungUniversity/Fall 2023/STAT 386/ST386_Final_Project/Scraped_Data/Viking_war_artifacts.csv')\n",
    "\n",
    "# unpack json\n",
    "dataset['Extra Details'] = dataset['Extra Details'].map(json.loads)\n",
    "war_artifacts_exploded = pd.json_normalize(dataset.to_dict(orient='records'))\n",
    "\n",
    "# drop rows that are not at least 25% populated\n",
    "cleaned_war_artifacts = drop_columns_with_fewer_nans(war_artifacts_exploded, \"prop\", 0.25)\n",
    "\n",
    "# Removing 'Extra Details.' prefix from column names\n",
    "cleaned_war_artifacts.columns = cleaned_war_artifacts.columns.str.replace('Extra Details.', '', regex=False)\n",
    "\n",
    "# Applying the function to your dataframe\n",
    "cleaned_war_artifacts = drop_duplicate_columns(cleaned_war_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### UNPACK JSON: TRADE ARTIFACTS\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('/Users/aly.milne/Library/CloudStorage/OneDrive-BrighamYoungUniversity/Fall 2023/STAT 386/ST386_Final_Project/Scraped_Data/Viking_trade_artifacts.csv')\n",
    "\n",
    "# unpack json\n",
    "dataset['Extra Details'] = dataset['Extra Details'].map(json.loads)\n",
    "trade_artifacts_exploded = pd.json_normalize(dataset.to_dict(orient='records'))\n",
    "\n",
    "# drop rows that are not at least 25% populated\n",
    "cleaned_trade_artifacts = drop_columns_with_fewer_nans(trade_artifacts_exploded, \"prop\", 0.25)\n",
    "\n",
    "# Removing 'Extra Details.' prefix from column names\n",
    "cleaned_trade_artifacts.columns = cleaned_trade_artifacts.columns.str.replace('Extra Details.', '', regex=False)\n",
    "\n",
    "# Applying the function to your dataframe\n",
    "cleaned_trade_artifacts = drop_duplicate_columns(cleaned_trade_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize the translator and cache\n",
    "translator = Translator()\n",
    "translations_cache = defaultdict(str)\n",
    "\n",
    "# Function to batch translate a list of texts\n",
    "def batch_translate(texts, src='sv', dest='en'):\n",
    "    # Filter out None values and ensure text is string\n",
    "    filtered_texts = [str(text) for text in texts if pd.notna(text)]\n",
    "    \n",
    "    # Batch processing and caching\n",
    "    batch_size = 10  # Adjust batch size as needed\n",
    "    for i in range(0, len(filtered_texts), batch_size):\n",
    "        batch = filtered_texts[i:i+batch_size]\n",
    "        untranslated_batch = [text for text in batch if text not in translations_cache]\n",
    "\n",
    "        if untranslated_batch:\n",
    "            try:\n",
    "                translations = translator.translate(untranslated_batch, src=src, dest=dest)\n",
    "                for text, translation in zip(untranslated_batch, translations):\n",
    "                    translations_cache[text] = translation.text\n",
    "            except Exception as e:  # General exception catch\n",
    "                print(f\"Error during translation: {e}\")\n",
    "                for text in untranslated_batch:\n",
    "                    translations_cache[text] = text\n",
    "\n",
    "        time.sleep(0.5)  # Respect rate limits\n",
    "\n",
    "    return [translations_cache[text] for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating column: Föremålsbenämning\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Translating column: Föremålsnr.\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m text_columns:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslating column: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m         df[column \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Translated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df_trade_translate\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[45], line 29\u001b[0m, in \u001b[0;36mbatch_translate\u001b[0;34m(texts, src, dest)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m untranslated_batch:\n\u001b[1;32m     27\u001b[0m                 translations_cache[text] \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Respect rate limits\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [translations_cache[text] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "###### TRANSLATE\n",
    "# Load your datasets\n",
    "df_trade_translate = cleaned_trade_artifacts\n",
    "df_war_translate = cleaned_war_artifacts\n",
    "\n",
    "# Identify text columns in the dataframes\n",
    "text_columns_trade = df_trade_translate.select_dtypes(include=['object']).columns\n",
    "text_columns_war = df_war_translate.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Translate text columns\n",
    "for df, text_columns in [(df_trade_translate, text_columns_trade), (df_war_translate, text_columns_war)]:\n",
    "    for column in text_columns:\n",
    "        print(f\"Translating column: {column}\")\n",
    "        df[column + '_Translated'] = batch_translate(df[column].tolist())\n",
    "\n",
    "df_trade_translate.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode(location):\n",
    "    \"\"\" Geocode a location using Nominatim API. \"\"\"\n",
    "    url = 'https://nominatim.openstreetmap.org/search'\n",
    "    headers = {\n",
    "        'User-Agent': 'alyanngirl@gmail.com'\n",
    "    }\n",
    "    params = {\n",
    "        'q': location,\n",
    "        'format': 'json'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        if results:\n",
    "            return results[0]['lat'], results[0]['lon']\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### GET LOCATIONS: WAR ARTIFACTS\n",
    "# Add columns for latitude and longitude\n",
    "cleaned_war_artifacts['latitude'] = None\n",
    "cleaned_war_artifacts['longitude'] = None\n",
    "\n",
    "# Iterate over the DataFrame and geocode each location\n",
    "for index, row in cleaned_war_artifacts.iterrows():\n",
    "    location = row['Plats']\n",
    "    lat, lon = geocode(location)\n",
    "    cleaned_war_artifacts.at[index, 'latitude'] = lat\n",
    "    cleaned_war_artifacts.at[index, 'longitude'] = lon\n",
    "\n",
    "    # Respect Nominatim's usage policy\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "cleaned_war_artifacts.to_csv('/Scraped_Data/war_w_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### GET LOCATIONS: TRADE ARTIFACTS\n",
    "# Add columns for latitude and longitude\n",
    "cleaned_trade_artifacts['latitude'] = None\n",
    "cleaned_trade_artifacts['longitude'] = None\n",
    "\n",
    "# Iterate over the DataFrame and geocode each location\n",
    "for index, row in cleaned_trade_artifacts.iterrows():\n",
    "    location = row['Plats']\n",
    "    lat, lon = geocode(location)\n",
    "    cleaned_trade_artifacts.at[index, 'latitude'] = lat\n",
    "    cleaned_trade_artifacts.at[index, 'longitude'] = lon\n",
    "\n",
    "    # Respect Nominatim's usage policy\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "cleaned_trade_artifacts.to_csv('/Scraped_Data/trade_w_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternates: \n",
    "# https://samlingar.shm.se/sok?type=object&productionPeriod=Vikingatid&hasImage=1&category=Arkeologisk%20samling&category=Vapen%20och%20rustningar&listType=archaeological&rows=500&offset=0\n",
    "# https://samlingar.shm.se/sok?type=object&productionPeriod=Vikingatid&hasImage=1&category=Arkeologisk%20samling&category=Handel%20och%20v%C3%A4rdem%C3%A4tare&listType=archaeological&rows=300&offset=0\n",
    "# https://samlingar.shm.se/sok?type=object&query=Vikingatid&listType=archaeological&rows=1000&offset=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TRANSLATE: TRADE ARTIFACTS\n",
    "# Columns to translate\n",
    "columns_to_translate = cleaned_trade_artifacts.columns.to_list()\n",
    "\n",
    "translated_trade = []\n",
    "\n",
    "# Translate the columns\n",
    "for column in columns_to_translate:\n",
    "    cleaned_trade_artifacts[column] = cleaned_trade_artifacts[column].apply(lambda x: translate_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "cleaned_trade_artifacts.head(5)\n",
    "\n",
    "# Save the translated dataframe to a new CSV file\n",
    "# cleaned_trade_artifacts.to_csv('translated_viking_trade_artifacts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "Error during translation: the JSON object must be str, bytes or bytearray, not NoneType\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use .loc to assign the values back to avoid SettingWithCopyWarning\u001b[39;00m\n\u001b[1;32m     14\u001b[0m cleaned_war_artifacts\u001b[38;5;241m.\u001b[39mloc[start:end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, column \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Translated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m translated_texts\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### TRANSLATE: WAR ARTIFACTS\n",
    "text_columns = cleaned_war_artifacts.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Translate each text column\n",
    "for column in text_columns:\n",
    "    # Process the DataFrame in chunks\n",
    "    chunk_size = 100  # Adjust based on your data and rate limits\n",
    "    for start in range(0, cleaned_war_artifacts.shape[0], chunk_size):\n",
    "        end = start + chunk_size\n",
    "        df_slice = cleaned_war_artifacts[start:end]\n",
    "        translated_texts = batch_translate(df_slice[column].astype(str).tolist())\n",
    "        \n",
    "        # Use .loc to assign the values back to avoid SettingWithCopyWarning\n",
    "        cleaned_war_artifacts.loc[start:end-1, column + '_Translated'] = translated_texts\n",
    "        time.sleep(1)  # Respect rate limits\n",
    "\n",
    "\n",
    "\n",
    "# Save the translated DataFrame to a new file\n",
    "# translated_df.to_csv('/path/to/your/translated_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Translate the columns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns_to_translate:\n\u001b[0;32m----> 9\u001b[0m     cleaned_war_artifacts[column] \u001b[38;5;241m=\u001b[39m \u001b[43mcleaned_war_artifacts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m cleaned_war_artifacts\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Translate the columns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns_to_translate:\n\u001b[0;32m----> 9\u001b[0m     cleaned_war_artifacts[column] \u001b[38;5;241m=\u001b[39m cleaned_war_artifacts[column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[1;32m     11\u001b[0m cleaned_war_artifacts\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mtranslate_text\u001b[0;34m(text, src, dest)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_text\u001b[39m(text, src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msv\u001b[39m\u001b[38;5;124m'\u001b[39m, dest\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# In case of an error, return original text\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/googletrans/client.py:194\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid destination language\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    193\u001b[0m origin \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m--> 194\u001b[0m data, response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m token_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    197\u001b[0m square_bracket_counts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/googletrans/client.py:120\u001b[0m, in \u001b[0;36mTranslator._translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    109\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf.req\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_rpc_request(text, dest, src),\n\u001b[1;32m    111\u001b[0m }\n\u001b[1;32m    112\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrpcids\u001b[39m\u001b[38;5;124m'\u001b[39m: RPC_ID,\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbl\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboq_translate-webserver_20201207.13_p0\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    119\u001b[0m }\n\u001b[0;32m--> 120\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_Exception:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected status code \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    124\u001b[0m         r\u001b[38;5;241m.\u001b[39mstatus_code, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_urls))\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpx/_client.py:824\u001b[0m, in \u001b[0;36mClient.post\u001b[0;34m(self, url, data, files, json, params, headers, cookies, auth, allow_redirects, timeout)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    812\u001b[0m     url: URLTypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m     timeout: typing\u001b[38;5;241m.\u001b[39mUnion[TimeoutTypes, UnsetType] \u001b[38;5;241m=\u001b[39m UNSET,\n\u001b[1;32m    823\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpx/_client.py:600\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, data, files, json, params, headers, cookies, auth, allow_redirects, timeout)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    577\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: typing\u001b[38;5;241m.\u001b[39mUnion[TimeoutTypes, UnsetType] \u001b[38;5;241m=\u001b[39m UNSET,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    590\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    591\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    592\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         cookies\u001b[38;5;241m=\u001b[39mcookies,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpx/_client.py:620\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, allow_redirects, timeout)\u001b[0m\n\u001b[1;32m    616\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timeout, UnsetType) \u001b[38;5;28;01melse\u001b[39;00m Timeout(timeout)\n\u001b[1;32m    618\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_auth(request, auth)\n\u001b[0;32m--> 620\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpx/_client.py:647\u001b[0m, in \u001b[0;36mClient.send_handling_redirects\u001b[0;34m(self, request, auth, timeout, allow_redirects, history)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(history) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_redirects:\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TooManyRedirects()\n\u001b[0;32m--> 647\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m response\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(history)\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mis_redirect:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpx/_client.py:684\u001b[0m, in \u001b[0;36mClient.send_handling_auth\u001b[0;34m(self, request, history, auth, timeout)\u001b[0m\n\u001b[1;32m    682\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 684\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mrequires_response_body:\n\u001b[1;32m    686\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpx/_client.py:714\u001b[0m, in \u001b[0;36mClient.send_single_request\u001b[0;34m(self, request, timeout)\u001b[0m\n\u001b[1;32m    705\u001b[0m transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport_for_url(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    708\u001b[0m     (\n\u001b[1;32m    709\u001b[0m         http_version,\n\u001b[1;32m    710\u001b[0m         status_code,\n\u001b[1;32m    711\u001b[0m         reason_phrase,\n\u001b[1;32m    712\u001b[0m         headers,\n\u001b[1;32m    713\u001b[0m         stream,\n\u001b[0;32m--> 714\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# Add the original request to any HTTPError unless\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;66;03m# there'a already a request attached in the case of\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;66;03m# a ProxyError.\u001b[39;00m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m_request \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:152\u001b[0m, in \u001b[0;36mSyncConnectionPool.request\u001b[0;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[1;32m    149\u001b[0m         logger\u001b[38;5;241m.\u001b[39mtrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreuse connection=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NewConnectionRequired:\n\u001b[1;32m    156\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_sync/connection.py:78\u001b[0m, in \u001b[0;36mSyncHTTPConnection.request\u001b[0;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     75\u001b[0m logger\u001b[38;5;241m.\u001b[39mtrace(\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnection.request method=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m url=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m headers=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method, url, headers\n\u001b[1;32m     77\u001b[0m )\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_sync/http2.py:118\u001b[0m, in \u001b[0;36mSyncHTTP2Connection.request\u001b[0;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreams[stream_id] \u001b[38;5;241m=\u001b[39m h2_stream\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevents[stream_id] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh2_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_streams_semaphore\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_sync/http2.py:292\u001b[0m, in \u001b[0;36mSyncHTTP2Stream.request\u001b[0;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_body(stream, timeout)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# Receive the response.\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m status_code, headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m reason_phrase \u001b[38;5;241m=\u001b[39m get_reason_phrase(status_code)\n\u001b[1;32m    294\u001b[0m stream \u001b[38;5;241m=\u001b[39m SyncByteStream(\n\u001b[1;32m    295\u001b[0m     iterator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody_iter(timeout), close_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed\n\u001b[1;32m    296\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_sync/http2.py:344\u001b[0m, in \u001b[0;36mSyncHTTP2Stream.receive_response\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03mRead the response status and headers from the network.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h2\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39mResponseReceived):\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_sync/http2.py:197\u001b[0m, in \u001b[0;36mSyncHTTP2Connection.wait_for_event\u001b[0;34m(self, stream_id, timeout)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_lock:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevents[stream_id]:\n\u001b[0;32m--> 197\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevents[stream_id]\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_sync/http2.py:204\u001b[0m, in \u001b[0;36mSyncHTTP2Connection.receive_events\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceive_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: TimeoutDict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Read some data from the network, and update the H2 state.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh2_state\u001b[38;5;241m.\u001b[39mreceive_data(data)\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/site-packages/httpcore/_backends/sync.py:62\u001b[0m, in \u001b[0;36mSyncSocketStream.read\u001b[0;34m(self, n, timeout)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msettimeout(read_timeout)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/stat386/lib/python3.10/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### TRANSLATE: TRADE ARTIFACTS\n",
    "# Split the DataFrame into smaller chunks if it's very large\n",
    "chunk_size = 100  # Adjust the chunk size based on your data and rate limits\n",
    "chunks = [cleaned_trade_artifacts[i:i + chunk_size] for i in range(0, cleaned_trade_artifacts.shape[0], chunk_size)]\n",
    "\n",
    "# Process each chunk\n",
    "for chunk in chunks:\n",
    "    chunk['Translated_Description'] = batch_translate(chunk['Description'].tolist())\n",
    "    time.sleep(1)  # Respect rate limits\n",
    "\n",
    "# Concatenate chunks back into a single DataFrame\n",
    "translated_trade_df = pd.concat(chunks)\n",
    "translated_trade_df.head(5)\n",
    "\n",
    "# Save the translated DataFrame to a new file\n",
    "# translated_df.to_csv('/path/to/your/translated_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
